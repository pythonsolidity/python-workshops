{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WOw8yMd1VlnD"
   },
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NvUGC8QQV6bV"
   },
   "source": [
    "### Importing the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wfFEXZC0WS-V"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fhYaZ-ENV_c5"
   },
   "source": [
    "### Reading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aqHTg9bxWT_u"
   },
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('startups.csv')\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate Independent variables (X) and dependent variable (y)\n",
    "\n",
    "X = dataset.iloc[:, 0:4].values\n",
    "y = dataset.iloc[:, 4].values\n",
    "\n",
    "print(X,'\\n\\n', y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace missing values by the column/variable average (mean)\n",
    "# Import Class --> Create Object --> Fit Object to Data --> Transform Data\n",
    "\n",
    "from sklearn.impute import SimpleImputer                            #import the SimpleImputer class\n",
    "imputer = SimpleImputer(missing_values=np.nan, strategy='mean')     #create the imputer object\n",
    "\n",
    "imputer.fit(X[:, 0:3])                          #fit the object to the data\n",
    "X[:, 0:3] = imputer.transform(X[:, 0:3])        #transform data\n",
    "\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoding categorical variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoding independent variables\n",
    "# Import Class --> Create Object --> Fit Object to Data --> Transform Data\n",
    "\n",
    "from sklearn.compose import ColumnTransformer       # import class\n",
    "from sklearn.preprocessing import OneHotEncoder     # import class\n",
    "\n",
    "ct = ColumnTransformer(transformers=[('encoder', OneHotEncoder(drop = 'first'), [3])], remainder='passthrough')    \n",
    "#create object\n",
    "\n",
    "X = np.array(ct.fit_transform(X))                   # fit object to data and transform data\n",
    "\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adjusting the scales of independent variables \n",
    "# Import Class --> Create Object --> Fit Object to Data --> Transform Data\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler   # import class\n",
    "sc = StandardScaler()                              # create object\n",
    "X = sc.fit_transform(X)                            # fit and transform \n",
    "\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(X)\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3abSxRqvWEIB"
   },
   "source": [
    "### Splitting the dataset into the Training set and Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hm48sif-WWsh"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Artificial Neural Net (ANN) for Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We use ANNs. \n",
    "# Can also use linear, polynomial, support vector, decision trees or random forest regression.  \n",
    "\n",
    "# Import Class --> Create Object --> Fit Object to Data --> Predict\n",
    "\n",
    "import tensorflow as tf               # import class\n",
    "from tensorflow import keras\n",
    "\n",
    "regressor = keras.Sequential([\n",
    "    tf.keras.layers.Dense(units = 20, input_dim=5, activation='relu'),\n",
    "    tf.keras.layers.Dense(units = 20, activation='relu'),\n",
    "    tf.keras.layers.Dense(units = 20, activation='relu'),\n",
    "    tf.keras.layers.Dense(units = 10, activation='relu'),\n",
    "    tf.keras.layers.Dense(units = 1, activation = 'linear')\n",
    "])                                                         # create object with the required layers\n",
    "\n",
    "regressor.compile(\n",
    "              loss='mean_squared_error',\n",
    "              optimizer=tf.keras.optimizers.RMSprop(0.01),\n",
    "              batch_size=20,\n",
    "              metrics=['mean_absolute_error']\n",
    ")                                                          # compile object selecting options\n",
    "\n",
    "regressor.fit(X_train, y_train, epochs= 500)               # fit object and decide the number of epochs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make predictions for test data\n",
    "\n",
    "y_pred = regressor.predict(X_test).flatten()    # predict (flatten() reshapes y_pred to a one-dimensional array)\n",
    "\n",
    "err = abs(y_test - y_pred)\n",
    "df = pd.DataFrame({'y_pred': y_pred, 'y_test': y_test, 'error': err})     # compare\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# determine model accuracy on the test set\n",
    "\n",
    "loss, mae = regressor.evaluate(X_test, y_test, verbose=0)\n",
    "print('Mean Absolute Error =', mae)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graphing (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.bar(range(10), err)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.bar(range(10), y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Forecasting (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What is the profit for \n",
    "# a California startup spending 10,000 on R&D, 50,000 on Administration and 10,000 on Marketing\n",
    "# What happens if they spend 100,000 on R&D?\n",
    "\n",
    "Z = sc.transform([[0, 0, 10000, 50000, 10000]])     # scale data using .transform() method but NOT .fit_transform()\n",
    "\n",
    "prediction = regressor.predict(Z)\n",
    "print('Scaled features = ', Z, ', Forecast = ', prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyOD2/gZgY69JdiiGJVNfu7s",
   "collapsed_sections": [],
   "name": "data_preprocessing_template.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
